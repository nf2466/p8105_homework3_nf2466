---
title: "Homework 2"
author: Nancy Fang (nf2466)
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---
```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
knitr::opts_chunk$set(
	fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```
### Problem 1
```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```


Let's make a plot

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


Let's make a table!!

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```


Apples vs ice cream..

```{r}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```
### Problem 2

Load the dataset and tidy
```{r}
accel_df=
  read_csv("./data/accel_data.csv") %>%
  janitor::clean_names()%>%
  pivot_longer(activity_1:activity_1440, names_to = "activity_minute", names_prefix = "activity_", values_to = "activity_count")%>%
  mutate(activity_minute = as.numeric(activity_minute),
         day_id=as.factor(day_id),
         day=as.factor(day),
  day = factor(day, levels = str_c(c("Mon", "Tues", "Wednes", "Thurs", "Fri", "Satur", "Sun"),"day"))
  )%>%
  arrange(week, day)%>%
  mutate(
  day_type=recode(day, "Saturday" = "weekend", "Sunday" = "weekend", 
                  "Monday" = "weekday", "Tuesday" = "weekday", "Wednesday" = "weekday", 
                  "Thursday" = "weekday","Friday" = "weekday")
  )
   
```
Part b: Now, aggregate total day activity count.

```{r}

accel_df%>%
  group_by(week,day)%>%
  summarize(count_total=sum(activity_count))%>%
  pivot_wider(
    names_from= day,
    values_from = count_total
  )%>%
  knitr::kable()
```
There doesn't appear to be a strong pattern in terms of the total activity count over the 5 weeks. Overall, the activity total appears highest on Mondays and lowest on Saturdays.

Part c
```{r}
 accel_df_p =
  accel_df %>%
  ggplot(aes(x = activity_minute, y = activity_count, color = day)) + 
   geom_smooth(se=FALSE) +
  labs(
    title = "Daily activity by day",
    x = "Minutes in a day (24 hours)",
    y = "Activity count"
  )

ggsave("accel_df_p.pdf", accel_df_p, width = 8, height = 5)

accel_df_p

```

It appears that there is an expected pattern of low activity during sleeping hours and more activity during the middle of the day (between minute 500-1000). We also see that on average, there is more activity in the morning/afternoon on Sunday and more activity in the evening time on Fridays.

---
###Problem 3

Download the NOAA dataset from P8105
```{r}
library(p8105.datasets)
data("ny_noaa")

```
In this dataset, there are `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns. There are `r ny_noaa%>%distinct(id)%>%count()` distinct locations in New York state. The variables also include the date of data collection, between `r min(ny_noaa$date)` and `r max(ny_noaa$date)`, precipitation, snowfall, snow depth, max temp and min temp in Celsius. There are `r sum(is.na(ny_noaa$prcp))` missing values for precipitation, `r sum(is.na(ny_noaa$snow))` missing values for snowfall, `r sum(is.na(ny_noaa$snwd))` missing values for snow depth, `r sum(is.na(ny_noaa$tmax))` missing values for max temp and `r sum(is.na(ny_noaa$tmin))` missing values for min temp.

Data cleaning: Do some data cleaning. Create separate variables for year, month, and day. Ensure observations for temperature, precipitation, and snowfall are given in reasonable units. For snowfall, what are the most commonly observed values? Why?
```{r}
ny_noaa%>%
  janitor::clean_names()%>%
  separate(date, into = c('year','month','day')) %>%
  mutate(month = month.abb[as.factor(month)]) %>%
  mutate_at(vars(year, day, tmax, tmin), as.numeric)
            
```


